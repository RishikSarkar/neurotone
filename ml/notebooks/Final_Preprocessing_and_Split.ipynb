{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7f8644-877c-41e8-82b7-b6f92486effd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working within Base Dir: ..\\data\\combined\n",
      "Temporary Processing Dir: ..\\data\\combined\\temp_processing\n",
      "Final Metadata Dir: ..\\data\\processed\n",
      "Target Segment Duration: 20s\n",
      "Minimum Segment Duration: 2s\n",
      "Segment Overlap: 1s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split # Use simple random split\n",
    "import numpy as np\n",
    "import uuid # For unique IDs\n",
    "import shutil # For moving final files\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Base directory\n",
    "root_dir = Path('../')\n",
    "data_dir = root_dir / 'data'\n",
    "\n",
    "# INPUT/OUTPUT Base Directory (Processing IN-PLACE within 'combined')\n",
    "combined_base_dir = data_dir / 'combined'\n",
    "dementia_dir = combined_base_dir / 'dementia'\n",
    "nodem_dir = combined_base_dir / 'nodementia'\n",
    "\n",
    "# TEMP directory for intermediate processing\n",
    "temp_dir = combined_base_dir / 'temp_processing'\n",
    "\n",
    "# Metadata output directory\n",
    "metadata_dir = data_dir / 'processed' # Save final splits here\n",
    "\n",
    "# Audio Processing Settings\n",
    "TARGET_SAMPLE_RATE = 16000\n",
    "TARGET_FORMAT = \"wav\"\n",
    "\n",
    "# Segmentation Settings\n",
    "SEGMENT_DURATION_S = 20 # Target duration\n",
    "MIN_SEGMENT_DURATION_S = 2  # Discard segments shorter than this\n",
    "OVERLAP_S = 1 # Overlap\n",
    "\n",
    "# --- Ensure Directories Exist ---\n",
    "dementia_dir.mkdir(parents=True, exist_ok=True)\n",
    "nodem_dir.mkdir(parents=True, exist_ok=True)\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "metadata_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Working within Base Dir: {combined_base_dir}\")\n",
    "print(f\"Temporary Processing Dir: {temp_dir}\")\n",
    "print(f\"Final Metadata Dir: {metadata_dir}\")\n",
    "print(f\"Target Segment Duration: {SEGMENT_DURATION_S}s\")\n",
    "print(f\"Minimum Segment Duration: {MIN_SEGMENT_DURATION_S}s\")\n",
    "print(f\"Segment Overlap: {OVERLAP_S}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505a9678-0ed0-4775-95d9-1e7ef328def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 2: Cleanup Non-Audio Files\n",
    "\n",
    "# print(\"\\n--- Cleaning up non-audio files ---\")\n",
    "# allowed_extensions = ['.wav', '.mp3', '.flac']\n",
    "# files_deleted = 0\n",
    "\n",
    "# for directory in [dementia_dir, nodem_dir]:\n",
    "#     print(f\"Scanning {directory}...\")\n",
    "#     if not directory.is_dir():\n",
    "#         print(f\"Warning: Directory not found: {directory}\")\n",
    "#         continue\n",
    "#     for item_path in list(directory.iterdir()): # Use list to avoid issues while deleting\n",
    "#         if item_path.is_file():\n",
    "#             if item_path.suffix.lower() not in allowed_extensions:\n",
    "#                 print(f\"  Deleting non-audio file: {item_path.name}\")\n",
    "#                 try:\n",
    "#                     item_path.unlink()\n",
    "#                     files_deleted += 1\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"    Error deleting {item_path.name}: {e}\")\n",
    "#         # Optional: remove empty subdirectories if any exist? For now, only files.\n",
    "\n",
    "# print(f\"\\nCleanup complete. Deleted {files_deleted} non-audio files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7257f5d3-5486-477f-981e-31d557c584da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 3: Standardize, Segment, Replace/Delete Originals\n",
    "\n",
    "# print(\"\\n--- Standardizing format and segmenting long files ---\")\n",
    "\n",
    "# all_processed_paths = [] # Keep track of final files generated in this step\n",
    "# all_errors = []\n",
    "# files_processed_count = 0\n",
    "# segments_created_count = 0\n",
    "# short_files_deleted_count = 0\n",
    "# long_files_replaced_count = 0\n",
    "# valid_short_files_kept_count = 0\n",
    "\n",
    "\n",
    "# # Use a temporary location for ffmpeg output before segmentation/moving\n",
    "# temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for directory in [dementia_dir, nodem_dir]:\n",
    "#     print(f\"\\nProcessing directory: {directory}\")\n",
    "#     if not directory.is_dir():\n",
    "#         print(f\"Warning: Directory not found: {directory}\")\n",
    "#         continue\n",
    "\n",
    "#     # Get list of current audio files before processing starts\n",
    "#     current_audio_files = [p for p in directory.iterdir() if p.is_file() and p.suffix.lower() in ['.wav', '.mp3', '.flac']]\n",
    "\n",
    "#     for input_path in tqdm(current_audio_files, desc=f\"Processing {directory.name}\"):\n",
    "#         files_processed_count += 1\n",
    "#         original_name_stem = input_path.stem\n",
    "#         original_suffix = input_path.suffix\n",
    "#         temp_standardized_wav_path = temp_dir / f\"{original_name_stem}_tempstandard.wav\"\n",
    "#         processed_successfully = False\n",
    "\n",
    "#         try:\n",
    "#             # 1. Standardize to 16kHz mono WAV in temp dir\n",
    "#             convert_command = [\n",
    "#                 \"ffmpeg\", \"-i\", str(input_path),\n",
    "#                 \"-ar\", str(TARGET_SAMPLE_RATE), \"-ac\", \"1\",\n",
    "#                 \"-vn\", \"-loglevel\", \"error\", \"-y\",\n",
    "#                 str(temp_standardized_wav_path)\n",
    "#             ]\n",
    "#             subprocess.run(convert_command, check=True, capture_output=True, timeout=300)\n",
    "\n",
    "#             # 2. Get duration of standardized file\n",
    "#             info = sf.info(temp_standardized_wav_path)\n",
    "#             duration = info.duration\n",
    "#             total_frames = info.frames\n",
    "#             if info.samplerate != TARGET_SAMPLE_RATE or info.channels != 1:\n",
    "#                  raise ValueError(f\"ffmpeg conversion incorrect format: {info.samplerate}Hz, {info.channels}ch\")\n",
    "\n",
    "#             # 3. Decide action based on duration\n",
    "#             if duration < MIN_SEGMENT_DURATION_S:\n",
    "#                 # Delete original file, discard temp\n",
    "#                 print(f\"  Discarding {input_path.name} (duration {duration:.2f}s < {MIN_SEGMENT_DURATION_S}s)\")\n",
    "#                 input_path.unlink() # Delete original\n",
    "#                 short_files_deleted_count += 1\n",
    "#                 processed_successfully = True # Processed in the sense of deciding its fate\n",
    "\n",
    "#             elif duration <= SEGMENT_DURATION_S:\n",
    "#                  # Keep this file, replace original with standardized temp version\n",
    "#                  final_path = directory / f\"{original_name_stem}.wav\" # Ensure final name is .wav\n",
    "#                  shutil.move(str(temp_standardized_wav_path), str(final_path))\n",
    "#                  # If original was not .wav, delete it\n",
    "#                  if input_path.suffix.lower() != '.wav' and input_path.exists():\n",
    "#                        input_path.unlink()\n",
    "#                  all_processed_paths.append(final_path)\n",
    "#                  valid_short_files_kept_count += 1\n",
    "#                  processed_successfully = True\n",
    "\n",
    "#             else: # Duration > SEGMENT_DURATION_S -> Segment\n",
    "#                  segment_len_frames = int(SEGMENT_DURATION_S * TARGET_SAMPLE_RATE)\n",
    "#                  min_segment_len_frames = int(MIN_SEGMENT_DURATION_S * TARGET_SAMPLE_RATE)\n",
    "#                  overlap_frames = int(OVERLAP_S * TARGET_SAMPLE_RATE)\n",
    "#                  step_frames = max(1, segment_len_frames - overlap_frames) # Ensure step > 0\n",
    "\n",
    "#                  current_pos_frames = 0\n",
    "#                  segment_index = 0\n",
    "#                  segments_saved_for_this_file = 0\n",
    "\n",
    "#                  with sf.SoundFile(temp_standardized_wav_path, 'r') as sndfile:\n",
    "#                      while current_pos_frames < total_frames:\n",
    "#                          read_start = current_pos_frames\n",
    "#                          read_frames = segment_len_frames\n",
    "#                          if read_start + read_frames > total_frames:\n",
    "#                              read_frames = total_frames - read_start\n",
    "\n",
    "#                          if read_frames >= min_segment_len_frames:\n",
    "#                              sndfile.seek(read_start)\n",
    "#                              segment_data = sndfile.read(frames=read_frames, dtype='float32')\n",
    "\n",
    "#                              segment_filename = f\"{original_name_stem}_seg{segment_index:04d}.wav\"\n",
    "#                              segment_output_path = directory / segment_filename # Save directly in original dir\n",
    "\n",
    "#                              sf.write(segment_output_path, segment_data, TARGET_SAMPLE_RATE)\n",
    "#                              all_processed_paths.append(segment_output_path)\n",
    "#                              segments_saved_for_this_file += 1\n",
    "#                              segments_created_count += 1\n",
    "#                              segment_index += 1\n",
    "\n",
    "#                          current_pos_frames += step_frames\n",
    "#                          if step_frames == 0: break # Safety break\n",
    "\n",
    "#                  if segments_saved_for_this_file > 0:\n",
    "#                      input_path.unlink() # Delete original file only if segments were saved\n",
    "#                      long_files_replaced_count += 1\n",
    "#                      processed_successfully = True\n",
    "#                  else:\n",
    "#                      # No valid segments created (maybe original was slightly > 20s but no segment >= 2s?)\n",
    "#                      print(f\"  Warning: No valid segments created for {input_path.name} (duration {duration:.2f}s). Discarding.\")\n",
    "#                      input_path.unlink() # Delete original\n",
    "#                      short_files_deleted_count +=1 # Count as discarded short file\n",
    "#                      processed_successfully = True\n",
    "\n",
    "\n",
    "#         except Exception as e:\n",
    "#             error_msg = f\"Failed processing {input_path.name}: {type(e).__name__} - {e}\"\n",
    "#             print(f\"  ERROR: {error_msg}\")\n",
    "#             all_errors.append(error_msg)\n",
    "#             # Don't delete original if processing failed, but delete temp\n",
    "#             temp_standardized_wav_path.unlink(missing_ok=True)\n",
    "\n",
    "#         finally:\n",
    "#             # Ensure temp file is always deleted unless moved\n",
    "#              if temp_standardized_wav_path.exists():\n",
    "#                   temp_standardized_wav_path.unlink(missing_ok=True)\n",
    "\n",
    "\n",
    "# # Cleanup empty temp directory\n",
    "# try:\n",
    "#     temp_dir.rmdir()\n",
    "# except OSError:\n",
    "#      print(f\"Warning: Temp directory {temp_dir} not empty or could not be removed.\")\n",
    "\n",
    "\n",
    "# print(\"\\n--- Standardization and Segmentation Summary ---\")\n",
    "# print(f\"Attempted to process {files_processed_count} original audio files.\")\n",
    "# print(f\"Kept/Standardized {valid_short_files_kept_count} files (duration <= {SEGMENT_DURATION_S}s).\")\n",
    "# print(f\"Segmented {long_files_replaced_count} long files into {segments_created_count} segments.\")\n",
    "# print(f\"Discarded {short_files_deleted_count} files (duration < {MIN_SEGMENT_DURATION_S}s or no valid segments).\")\n",
    "# print(f\"Encountered {len(all_errors)} errors.\")\n",
    "# if all_errors:\n",
    "#     print(\"Sample Errors:\")\n",
    "#     for err in all_errors[:10]: print(f\"  - {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f6fbffd-aae8-4231-8d73-f210cfe5609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 4: Rename Processed Files to Unique IDs and Add Duration\n",
    "\n",
    "# import uuid # Ensure uuid is imported\n",
    "# import hashlib # Re-import if needed\n",
    "\n",
    "# print(\"\\n--- Renaming processed files to unique IDs and recording duration ---\")\n",
    "\n",
    "# uuid_map = [] # To store mapping {uuid_str: {final_path, label, original_name, duration_seconds}}\n",
    "# rename_errors = []\n",
    "# files_renamed_count = 0\n",
    "# duration_read_errors = 0\n",
    "\n",
    "# # Scan directories for final .wav files to rename\n",
    "# print(\"Scanning directories for final .wav files...\")\n",
    "# final_wav_files = []\n",
    "# for directory in [dementia_dir, nodem_dir]:\n",
    "#      if directory.is_dir():\n",
    "#           final_wav_files.extend([p for p in directory.glob('*.wav') if p.is_file()])\n",
    "\n",
    "# print(f\"Found {len(final_wav_files)} .wav files.\")\n",
    "\n",
    "# for current_path in tqdm(final_wav_files, desc=\"Renaming and Reading Duration\"):\n",
    "#     original_name_for_map = current_path.name # Store name before potential rename\n",
    "#     duration_seconds = -1.0 # Default duration if error\n",
    "#     new_path = current_path # Assume no rename needed initially if already UUID\n",
    "\n",
    "#     try:\n",
    "#         # Check if already looks like a UUID\n",
    "#         is_already_uuid = len(current_path.stem) == 36 and '-' in current_path.stem\n",
    "\n",
    "#         if not is_already_uuid:\n",
    "#              # Generate new UUID name only if needed\n",
    "#              unique_id = str(uuid.uuid4())\n",
    "#              new_filename = f\"{unique_id}.wav\"\n",
    "#              new_path = current_path.parent / new_filename\n",
    "#              if new_path.exists(): # Extremely unlikely collision\n",
    "#                   unique_id = str(uuid.uuid4())\n",
    "#                   new_filename = f\"{unique_id}.wav\"\n",
    "#                   new_path = current_path.parent / new_filename\n",
    "#              # Rename the file\n",
    "#              current_path.rename(new_path)\n",
    "#              files_renamed_count += 1\n",
    "#         # else: use current_path as new_path\n",
    "\n",
    "#         # Get duration from the file (potentially renamed)\n",
    "#         try:\n",
    "#             info = sf.info(new_path)\n",
    "#             duration_seconds = info.duration\n",
    "#         except Exception as sf_err:\n",
    "#             print(f\"  Warning: Could not read duration for {new_path.name}: {sf_err}\")\n",
    "#             duration_read_errors += 1\n",
    "\n",
    "#         # Add info to map\n",
    "#         label = 1 if new_path.parent.name == 'dementia' else 0\n",
    "#         uuid_map.append({\n",
    "#             'uuid': new_path.stem, # UUID is the stem of the final path\n",
    "#             'final_path': str(new_path.relative_to(combined_base_dir)),\n",
    "#             'label': label,\n",
    "#             'original_name': original_name_for_map, # Name before rename\n",
    "#             'duration_seconds': duration_seconds\n",
    "#         })\n",
    "\n",
    "#     except Exception as e:\n",
    "#         error_msg = f\"Error processing {original_name_for_map}: {e}\"\n",
    "#         print(f\"  ERROR: {error_msg}\")\n",
    "#         rename_errors.append(error_msg)\n",
    "\n",
    "# # Save the mapping with duration\n",
    "# df_uuid_map = pd.DataFrame(uuid_map)\n",
    "# map_path = metadata_dir / \"uuid_mapping_with_duration.csv\" # New filename\n",
    "# df_uuid_map.to_csv(map_path, index=False)\n",
    "\n",
    "# print(\"\\n--- Renaming and Duration Summary ---\")\n",
    "# print(f\"Processed {len(final_wav_files)} .wav files.\")\n",
    "# print(f\"Renamed {files_renamed_count} files to unique IDs.\")\n",
    "# print(f\"Encountered {duration_read_errors} errors reading duration.\")\n",
    "# print(f\"Encountered {len(rename_errors)} other errors.\")\n",
    "# if rename_errors:\n",
    "#      print(\"Sample Other Errors:\")\n",
    "#      for err in rename_errors[:5]: print(f\"  - {err}\")\n",
    "# print(f\"UUID mapping with duration saved to: {map_path}\")\n",
    "# if not df_uuid_map.empty:\n",
    "#     print(df_uuid_map.head())\n",
    "# else:\n",
    "#     print(\"Warning: UUID map is empty. Check file processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb43cb3a-a41e-47e2-b6b1-a9b70abd4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 5: Filter Controls by Duration, Undersample Controls, and Split Data\n",
    "\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "\n",
    "# print(\"\\n--- Creating Final Balanced Metadata and Splitting ---\")\n",
    "\n",
    "# # --- Define Paths ---\n",
    "# metadata_dir = data_dir / 'processed' # Defined in Cell 1\n",
    "# combined_base_dir = data_dir / 'combined' # Defined in Cell 1\n",
    "# map_path = metadata_dir / \"uuid_mapping_with_duration.csv\" # LOAD THIS FILE\n",
    "\n",
    "# # Output Paths for final splits\n",
    "# final_train_meta_path = metadata_dir / 'train_meta_len_filtered_balanced.csv' # New descriptive name\n",
    "# final_val_meta_path = metadata_dir / 'val_meta_len_filtered_balanced.csv'   # New descriptive name\n",
    "# final_test_meta_path = metadata_dir / 'test_meta_len_filtered_balanced.csv'  # New descriptive name\n",
    "\n",
    "# # --- Load Mapping File with Duration ---\n",
    "# try:\n",
    "#     print(f\"Loading UUID map with duration from: {map_path}\")\n",
    "#     df_map = pd.read_csv(map_path)\n",
    "#     # Drop rows where duration could not be read\n",
    "#     df_map = df_map[df_map['duration_seconds'] >= 0].copy()\n",
    "#     if df_map.empty: raise ValueError(\"No valid entries after loading map.\")\n",
    "#     print(f\"Loaded {len(df_map)} samples with valid duration.\")\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"ERROR: Mapping file not found: {map_path}. Please run Cell 4 first.\")\n",
    "#     raise\n",
    "# except ValueError as e:\n",
    "#      print(f\"ERROR: {e}\")\n",
    "#      raise\n",
    "# except Exception as e:\n",
    "#     print(f\"ERROR loading mapping file: {e}\")\n",
    "#     raise\n",
    "\n",
    "\n",
    "# # --- Separate Dementia and Control Samples ---\n",
    "# df_dementia = df_map[df_map['label'] == 1].copy()\n",
    "# df_controls = df_map[df_map['label'] == 0].copy()\n",
    "# print(f\"Total Dementia Samples: {len(df_dementia)}\")\n",
    "# print(f\"Total Control Samples: {len(df_controls)}\")\n",
    "\n",
    "\n",
    "# # --- Filter Controls by Duration ---\n",
    "# min_duration_filter = 10.0 # Keep controls >= 10 seconds\n",
    "# print(f\"\\nFiltering control samples to keep duration >= {min_duration_filter}s...\")\n",
    "# df_controls_filtered = df_controls[df_controls['duration_seconds'] >= min_duration_filter].copy()\n",
    "# print(f\"Found {len(df_controls_filtered)} control samples >= {min_duration_filter}s (discarded {len(df_controls) - len(df_controls_filtered)}).\")\n",
    "\n",
    "# if df_controls_filtered.empty:\n",
    "#      raise ValueError(\"No control samples remaining after duration filter!\")\n",
    "\n",
    "\n",
    "# # --- Undersample Filtered Controls to Match Dementia Count ---\n",
    "# n_dementia = len(df_dementia)\n",
    "# n_controls_filtered = len(df_controls_filtered)\n",
    "\n",
    "# if n_controls_filtered >= n_dementia:\n",
    "#     print(f\"\\nUndersampling filtered controls from {n_controls_filtered} to match {n_dementia} dementia samples...\")\n",
    "#     df_controls_sampled = df_controls_filtered.sample(n=n_dementia, random_state=42)\n",
    "# else:\n",
    "#     # This case is unlikely given previous counts, but handle it\n",
    "#     print(f\"\\nWarning: Fewer filtered controls ({n_controls_filtered}) than dementia samples ({n_dementia}). Using all {n_controls_filtered} filtered controls.\")\n",
    "#     # To maintain balance here, we would have to undersample dementia, but the user wants all dementia.\n",
    "#     # So, we proceed with the imbalance if controls are the minority after filtering.\n",
    "#     df_controls_sampled = df_controls_filtered\n",
    "#     print(\"The final dataset will NOT be perfectly balanced by count.\")\n",
    "\n",
    "# # Combine final selected controls and all dementia samples\n",
    "# df_balanced_final = pd.concat([df_controls_sampled, df_dementia], ignore_index=True)\n",
    "# print(f\"\\nCreated final dataset with {len(df_balanced_final)} total samples:\")\n",
    "# print(f\"  Controls (>= {min_duration_filter}s): {len(df_controls_sampled)}\")\n",
    "# print(f\"  Dementia (All): {len(df_dementia)}\")\n",
    "\n",
    "\n",
    "# # --- Select final columns and Rename for Training ---\n",
    "# df_final_metadata = df_balanced_final[['final_path', 'label']].copy()\n",
    "# df_final_metadata.rename(columns={'final_path': 'relative_audio_path'}, inplace=True)\n",
    "\n",
    "\n",
    "# # --- Perform Random Split (Ignoring Speakers) ---\n",
    "# print(\"\\nPerforming random 80/10/10 split on the final dataset...\")\n",
    "\n",
    "# min_samples_per_class = df_final_metadata['label'].value_counts().min()\n",
    "# n_splits_possible = min(min_samples_per_class, 2) # Need at least 2 for stratify\n",
    "\n",
    "# if df_final_metadata.empty or len(df_final_metadata) < 4 or n_splits_possible < 2: # Need enough for train/val/test splits\n",
    "#     print(\"Error: Not enough data or classes for stratified splitting after filtering/sampling.\")\n",
    "# else:\n",
    "#     try:\n",
    "#         # Split off 20% for validation + test\n",
    "#         df_train, df_valtest = train_test_split(\n",
    "#             df_final_metadata,\n",
    "#             test_size=0.20,\n",
    "#             random_state=42,\n",
    "#             stratify=df_final_metadata['label']\n",
    "#         )\n",
    "\n",
    "#         # Check if valtest is sufficient for another stratified split\n",
    "#         min_samples_valtest = df_valtest['label'].value_counts().min() if not df_valtest.empty else 0\n",
    "#         if len(df_valtest) < 2 or min_samples_valtest < 2 :\n",
    "#             print(\"Warning: Not enough data/classes in val/test set for further stratified split. Splitting randomly.\")\n",
    "#             df_val, df_test = train_test_split(df_valtest, test_size=0.50, random_state=42) # No stratify if too small\n",
    "#         else:\n",
    "#             # Split the 20% into 10% validation and 10% test\n",
    "#             df_val, df_test = train_test_split(\n",
    "#                 df_valtest,\n",
    "#                 test_size=0.50,\n",
    "#                 random_state=42,\n",
    "#                 stratify=df_valtest['label']\n",
    "#             )\n",
    "\n",
    "#         # --- Save Final Metadata Splits ---\n",
    "#         df_train.to_csv(final_train_meta_path, index=False)\n",
    "#         df_val.to_csv(final_val_meta_path, index=False)\n",
    "#         df_test.to_csv(final_test_meta_path, index=False)\n",
    "\n",
    "#         print(\"\\n--- Final Split Summary ---\")\n",
    "#         print(f\"Train set: {len(df_train)} segments ({df_train['label'].sum()} dementia, {len(df_train)-df_train['label'].sum()} control).\")\n",
    "#         print(f\"Validation set: {len(df_val)} segments ({df_val['label'].sum()} dementia, {len(df_val)-df_val['label'].sum()} control).\")\n",
    "#         print(f\"Test set: {len(df_test)} segments ({df_test['label'].sum()} dementia, {len(df_test)-df_test['label'].sum()} control).\")\n",
    "#         print(f\"Saved Train metadata to: {final_train_meta_path}\")\n",
    "#         print(f\"Saved Validation metadata to: {final_val_meta_path}\")\n",
    "#         print(f\"Saved Test metadata to: {final_test_meta_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during splitting or saving: {e}\")\n",
    "\n",
    "\n",
    "# print(\"\\n--- Final Data Preparation Script Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20b9b8f-3f19-433d-91d5-f4543c93c154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying Sample Rates in Final Audio Directories ---\n",
      "Found 94489 total .wav files to check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking Sample Rates: 100%|█| 94489/94489 [11:21<00:00,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verification Summary ---\n",
      "Total .wav files checked: 94489\n",
      "Files with mismatched sample rate: 69\n",
      "Files that failed to read: 0\n",
      "\n",
      "Files with Mismatched Sample Rates:\n",
      "  - Path: nodementia\\04e77862-e76e-410a-bd32-aeb6e71c9e12.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\10e7f964-13b8-45b8-af02-e2c1b27aef6a.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\1221d439-f3b8-4800-b98f-31d21e652634.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\135d96ae-e170-4e22-bc80-7d66cd3208ed.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\15532063-fb79-4f63-833a-440680f1194f.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\15a0e730-4df9-4049-97c4-5cf9a88a29c9.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\18b42b10-874c-4022-b8d4-db3c4f73da7c.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\1953aeac-1cf4-4ec3-a67d-f3864334738d.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\24a7d59d-f21f-41d1-b059-ff5ef88d1f08.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\2eef3fd0-2b8d-46f4-a582-9a6de380d8f2.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\325a50c3-0f16-4998-9f2c-de480d89ff2e.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\3430264b-f8a5-4d3d-b99b-b5a271b80ed1.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\35a58774-9934-459f-ab01-ee515e4802d1.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\3cca8b3e-11e2-4ff5-85bf-ebbd5b5192d2.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\3dac4862-ec29-43b0-acfc-8cf433c18407.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\3e206f66-7906-4e9b-a784-6b62337c8127.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\3e6b6495-cad3-473a-ab21-1e9abd20709d.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\4b9590c6-a5f7-4a2e-9e76-306d7a60340e.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\57340ae5-58a9-4e8d-a725-0e5905b8cd73.wav, Found: 44100 Hz\n",
      "  - Path: nodementia\\5b982f13-cbc1-4472-bff0-5659679915d8.wav, Found: 44100 Hz\n",
      "... and 49 more.\n",
      "\n",
      "Issues found. You may need to re-run the preprocessing (Cell 3) or manually fix/delete problematic files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # Cell: Verify Audio Sample Rates\n",
    "\n",
    "# import soundfile as sf\n",
    "# from pathlib import Path\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# print(\"\\n--- Verifying Sample Rates in Final Audio Directories ---\")\n",
    "\n",
    "# # Get paths from Cell 1 (ensure Cell 1 was run)\n",
    "# if 'combined_base_dir' not in locals():\n",
    "#      print(\"ERROR: combined_base_dir not defined. Run Cell 1 first.\")\n",
    "#      # Define fallback if running standalone\n",
    "#      # combined_base_dir = Path('../data/combined')\n",
    "#      # TARGET_SAMPLE_RATE = 16000\n",
    "# else:\n",
    "#      dementia_dir = combined_base_dir / 'dementia'\n",
    "#      nodem_dir = combined_base_dir / 'nodementia'\n",
    "#      TARGET_SAMPLE_RATE = 16000 # Defined in Cell 1\n",
    "\n",
    "# mismatched_files = []\n",
    "# error_reading_files = []\n",
    "# total_files_checked = 0\n",
    "\n",
    "# # Combine file lists from both directories\n",
    "# all_wav_files = []\n",
    "# if dementia_dir.is_dir():\n",
    "#     all_wav_files.extend(list(dementia_dir.glob('*.wav')))\n",
    "# if nodem_dir.is_dir():\n",
    "#     all_wav_files.extend(list(nodem_dir.glob('*.wav')))\n",
    "\n",
    "# print(f\"Found {len(all_wav_files)} total .wav files to check...\")\n",
    "\n",
    "# for file_path in tqdm(all_wav_files, desc=\"Checking Sample Rates\"):\n",
    "#     if not file_path.is_file(): # Skip if it's somehow a directory\n",
    "#         continue\n",
    "\n",
    "#     total_files_checked += 1\n",
    "#     try:\n",
    "#         info = sf.info(file_path)\n",
    "#         if info.samplerate != TARGET_SAMPLE_RATE:\n",
    "#             mismatched_files.append({\n",
    "#                 'path': str(file_path.relative_to(combined_base_dir)),\n",
    "#                 'found_rate': info.samplerate,\n",
    "#                 'expected_rate': TARGET_SAMPLE_RATE\n",
    "#             })\n",
    "#     except Exception as e:\n",
    "#         error_reading_files.append({\n",
    "#             'path': str(file_path.relative_to(combined_base_dir)),\n",
    "#             'error': str(e)\n",
    "#         })\n",
    "\n",
    "# print(\"\\n--- Verification Summary ---\")\n",
    "# print(f\"Total .wav files checked: {total_files_checked}\")\n",
    "# print(f\"Files with mismatched sample rate: {len(mismatched_files)}\")\n",
    "# print(f\"Files that failed to read: {len(error_reading_files)}\")\n",
    "\n",
    "# if mismatched_files:\n",
    "#     print(\"\\nFiles with Mismatched Sample Rates:\")\n",
    "#     limit = 20 # Show first N mismatches\n",
    "#     for i, f_info in enumerate(mismatched_files):\n",
    "#         if i >= limit:\n",
    "#             print(f\"... and {len(mismatched_files) - limit} more.\")\n",
    "#             break\n",
    "#         print(f\"  - Path: {f_info['path']}, Found: {f_info['found_rate']} Hz\")\n",
    "\n",
    "# if error_reading_files:\n",
    "#     print(\"\\nFiles That Failed to Read:\")\n",
    "#     limit = 20 # Show first N errors\n",
    "#     for i, f_info in enumerate(error_reading_files):\n",
    "#          if i >= limit:\n",
    "#             print(f\"... and {len(error_reading_files) - limit} more.\")\n",
    "#             break\n",
    "#          print(f\"  - Path: {f_info['path']}, Error: {f_info['error']}\")\n",
    "\n",
    "# if not mismatched_files and not error_reading_files:\n",
    "#     print(\"\\nAll checked .wav files have the correct sample rate (16000 Hz).\")\n",
    "# else:\n",
    "#     print(\"\\nIssues found. You may need to re-run the preprocessing (Cell 3) or manually fix/delete problematic files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9503cf-41d2-41de-91f0-0a0602a5cae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resampling Mismatched Files ---\n",
      "Found 69 files to attempt resampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling Files: 100%|█| 69/69 [00:06<00:00, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resampling Summary ---\n",
      "Attempted to resample 69 files.\n",
      "Successfully resampled and replaced 69 files.\n",
      "Encountered 0 errors during resampling/verification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # Cell: Targeted Resampling of Mismatched Files\n",
    "\n",
    "# import soundfile as sf\n",
    "# from pathlib import Path\n",
    "# import subprocess\n",
    "# from tqdm import tqdm\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# print(\"\\n--- Resampling Mismatched Files ---\")\n",
    "\n",
    "# # Ensure variables from previous cells are available\n",
    "# if 'mismatched_files' not in locals() or not mismatched_files:\n",
    "#     print(\"ERROR: 'mismatched_files' list not found or empty. Run the verification cell first.\")\n",
    "# elif 'combined_base_dir' not in locals() or 'TARGET_SAMPLE_RATE' not in locals():\n",
    "#     print(\"ERROR: 'combined_base_dir' or 'TARGET_SAMPLE_RATE' not defined. Run Cell 1 first.\")\n",
    "# else:\n",
    "#     print(f\"Found {len(mismatched_files)} files to attempt resampling.\")\n",
    "#     resample_errors = []\n",
    "#     files_resampled_count = 0\n",
    "\n",
    "#     # Define a temporary directory for conversion output\n",
    "#     temp_resample_dir = combined_base_dir / \"temp_resampling\"\n",
    "#     temp_resample_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#     for file_info in tqdm(mismatched_files, desc=\"Resampling Files\"):\n",
    "#         relative_path = file_info['path']\n",
    "#         input_path = combined_base_dir / relative_path\n",
    "#         temp_output_path = temp_resample_dir / input_path.name # Use same name in temp dir\n",
    "\n",
    "#         if not input_path.is_file():\n",
    "#             print(f\"  Skipping (File not found): {input_path}\")\n",
    "#             resample_errors.append(f\"File not found: {relative_path}\")\n",
    "#             continue\n",
    "\n",
    "#         try:\n",
    "#             # Construct ffmpeg command to overwrite temp file\n",
    "#             command = [\n",
    "#                 \"ffmpeg\",\n",
    "#                 \"-i\", str(input_path),   # Input file\n",
    "#                 \"-ar\", str(TARGET_SAMPLE_RATE), # Target sample rate\n",
    "#                 \"-ac\", \"1\",            # Target channels (mono)\n",
    "#                 \"-vn\",                 # No video output\n",
    "#                 \"-loglevel\", \"error\",  # Show only errors\n",
    "#                 \"-y\",                  # Overwrite output without asking\n",
    "#                 str(temp_output_path)  # Output to temp file\n",
    "#             ]\n",
    "\n",
    "#             # Run ffmpeg\n",
    "#             subprocess.run(command, check=True, capture_output=True, timeout=300) # 5 min timeout\n",
    "\n",
    "#             # Verify the temporary output file\n",
    "#             try:\n",
    "#                  info = sf.info(temp_output_path)\n",
    "#                  if info.samplerate == TARGET_SAMPLE_RATE and info.channels == 1:\n",
    "#                       # Verification successful, replace original with temp file\n",
    "#                       shutil.move(str(temp_output_path), str(input_path))\n",
    "#                       files_resampled_count += 1\n",
    "#                  else:\n",
    "#                       raise ValueError(f\"Verification failed: Rate={info.samplerate}, Channels={info.channels}\")\n",
    "\n",
    "#             except Exception as verify_err:\n",
    "#                  error_msg = f\"Verification failed for {input_path.name} after conversion: {verify_err}\"\n",
    "#                  print(f\"  ERROR: {error_msg}\")\n",
    "#                  resample_errors.append(error_msg)\n",
    "#                  # Don't move the failed file, clean up temp\n",
    "#                  temp_output_path.unlink(missing_ok=True)\n",
    "\n",
    "\n",
    "#         except subprocess.CalledProcessError as e:\n",
    "#             error_msg = f\"ffmpeg failed for {input_path.name}: {e.stderr.decode('utf-8', errors='replace') if e.stderr else 'Unknown ffmpeg error'}\"\n",
    "#             print(f\"  ERROR: {error_msg}\")\n",
    "#             resample_errors.append(error_msg)\n",
    "#             temp_output_path.unlink(missing_ok=True) # Clean up failed temp file\n",
    "#         except Exception as e:\n",
    "#             error_msg = f\"Unexpected error resampling {input_path.name}: {e}\"\n",
    "#             print(f\"  ERROR: {error_msg}\")\n",
    "#             resample_errors.append(error_msg)\n",
    "#             temp_output_path.unlink(missing_ok=True) # Clean up failed temp file\n",
    "\n",
    "\n",
    "#     # Cleanup empty temp directory\n",
    "#     try:\n",
    "#         if not any(temp_resample_dir.iterdir()): # Only remove if empty\n",
    "#             temp_resample_dir.rmdir()\n",
    "#     except OSError:\n",
    "#          print(f\"Warning: Temp directory {temp_resample_dir} not empty or could not be removed.\")\n",
    "\n",
    "\n",
    "#     print(\"\\n--- Resampling Summary ---\")\n",
    "#     print(f\"Attempted to resample {len(mismatched_files)} files.\")\n",
    "#     print(f\"Successfully resampled and replaced {files_resampled_count} files.\")\n",
    "#     print(f\"Encountered {len(resample_errors)} errors during resampling/verification.\")\n",
    "#     if resample_errors:\n",
    "#         print(\"Sample Errors:\")\n",
    "#         for err in resample_errors[:10]: print(f\"  - {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc962e-a0bc-4c4f-be02-9afd66a32c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
